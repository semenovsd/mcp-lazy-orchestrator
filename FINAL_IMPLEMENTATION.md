# –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
src/mcp_orchestrator/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ server.py                    # Main MCP server (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π)
‚îú‚îÄ‚îÄ discovery.py                 # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
‚îú‚îÄ‚îÄ registry.py                  # –†–µ–µ—Å—Ç—Ä —Å–µ—Ä–≤–µ—Ä–æ–≤
‚îú‚îÄ‚îÄ capabilities.py              # Capabilities registry
‚îú‚îÄ‚îÄ analyzer.py                  # Task analyzer (keyword + semantic)
‚îú‚îÄ‚îÄ router.py                    # Semantic router
‚îú‚îÄ‚îÄ profiles.py                  # Server profiles
‚îú‚îÄ‚îÄ monitor.py                   # Usage monitor
‚îú‚îÄ‚îÄ telemetry.py                 # Observability
‚îî‚îÄ‚îÄ config.py                    # Configuration
```

---

## üîß –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

### 1. capabilities.py - Capabilities Registry

```python
"""
Capabilities Registry - —Å–≤—è–∑—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π —Å —Å–µ—Ä–≤–µ—Ä–∞–º–∏
"""

import yaml
from pathlib import Path
from typing import Optional, dict, Any
from dataclasses import dataclass, field


@dataclass
class ServerCapabilities:
    """Capabilities —Å–µ—Ä–≤–µ—Ä–∞"""
    name: str
    purpose: str
    covers_technologies: list[str] = field(default_factory=list)
    when_to_use: str = ""
    tools_preview: list[str] = field(default_factory=list)
    related_servers: list[str] = field(default_factory=list)
    auto_activate_with: list[str] = field(default_factory=list)


class CapabilitiesRegistry:
    """–†–µ–µ—Å—Ç—Ä capabilities —Å–µ—Ä–≤–µ—Ä–æ–≤"""
    
    def __init__(self, config_path: Optional[Path] = None):
        self.registry: dict[str, ServerCapabilities] = {}
        self.config_path = config_path or Path("capabilities/base.yaml")
        self._load_capabilities()
    
    def _load_capabilities(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å capabilities –∏–∑ YAML"""
        if self.config_path.exists():
            with open(self.config_path) as f:
                data = yaml.safe_load(f)
                for server_name, config in data.get("servers", {}).items():
                    self.registry[server_name] = ServerCapabilities(
                        name=server_name,
                        purpose=config.get("purpose", ""),
                        covers_technologies=config.get("covers_technologies", []),
                        when_to_use=config.get("when_to_use", ""),
                        tools_preview=config.get("tools_preview", []),
                        related_servers=config.get("related_servers", []),
                        auto_activate_with=config.get("auto_activate_with", [])
                    )
        else:
            # Fallback: –±–∞–∑–æ–≤—ã–µ capabilities
            self._load_default_capabilities()
    
    def _load_default_capabilities(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ capabilities"""
        defaults = {
            "context7": ServerCapabilities(
                name="context7",
                purpose="Up-to-date library documentation",
                covers_technologies=["redis", "postgres", "fastapi", "django", 
                                    "react", "vue", "kubernetes", "sqlalchemy"],
                when_to_use="BEFORE writing code - get current API docs",
                tools_preview=["resolve-library-id", "get-library-docs"],
                auto_activate_with=["redis", "postgres", "playwright", "github"]
            ),
            "redis": ServerCapabilities(
                name="redis",
                purpose="Redis database operations",
                covers_technologies=["caching", "sessions", "pub/sub", "queues"],
                when_to_use="Direct Redis commands and data management",
                tools_preview=["redis_get", "redis_set", "redis_del"],
                related_servers=["context7"]
            ),
            # ... –¥—Ä—É–≥–∏–µ —Å–µ—Ä–≤–µ—Ä—ã
        }
        self.registry.update(defaults)
    
    def get(self, server_name: str) -> Optional[ServerCapabilities]:
        """–ü–æ–ª—É—á–∏—Ç—å capabilities —Å–µ—Ä–≤–µ—Ä–∞"""
        return self.registry.get(server_name)
    
    def find_by_technology(self, technology: str) -> list[str]:
        """–ù–∞–π—Ç–∏ —Å–µ—Ä–≤–µ—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫—Ä—ã–≤–∞—é—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é"""
        technology_lower = technology.lower()
        matching = []
        
        for server_name, caps in self.registry.items():
            if any(tech.lower() == technology_lower 
                   for tech in caps.covers_technologies):
                matching.append(server_name)
        
        return matching
    
    def get_related_servers(self, server_name: str) -> list[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã"""
        caps = self.get(server_name)
        if caps:
            return caps.related_servers
        return []
```

### 2. router.py - Semantic Router

```python
"""
Semantic Router - —É–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ embeddings
"""

from typing import list, tuple
import logging

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sentence-transformers –¥–ª—è semantic matching
try:
    from sentence_transformers import SentenceTransformer
    HAS_SEMANTIC = True
except ImportError:
    HAS_SEMANTIC = False
    logging.warning("sentence-transformers not installed, using keyword matching only")


class SemanticRouter:
    """Semantic router –¥–ª—è —É–º–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–æ–≤"""
    
    def __init__(self, capabilities_registry):
        self.capabilities = capabilities_registry
        self.model = None
        
        if HAS_SEMANTIC:
            try:
                self.model = SentenceTransformer('all-MiniLM-L6-v2')
                self._build_index()
            except Exception as e:
                logging.warning(f"Failed to load semantic model: {e}")
                self.model = None
    
    def _build_index(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å embeddings –¥–ª—è —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        if not self.model:
            return
        
        self.server_embeddings = {}
        for server_name, caps in self.capabilities.registry.items():
            # –°–æ–∑–¥–∞—ë–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è embedding
            text = f"{caps.purpose} {' '.join(caps.covers_technologies)}"
            self.server_embeddings[server_name] = self.model.encode(text)
    
    def match_servers(
        self, 
        task_description: str, 
        top_k: int = 5
    ) -> list[tuple[str, float]]:
        """
        –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã –¥–ª—è –∑–∞–¥–∞—á–∏.
        
        Returns:
            List of (server_name, confidence_score) tuples
        """
        if self.model and hasattr(self, 'server_embeddings'):
            return self._semantic_match(task_description, top_k)
        else:
            return self._keyword_match(task_description, top_k)
    
    def _semantic_match(
        self, 
        task_description: str, 
        top_k: int
    ) -> list[tuple[str, float]]:
        """Semantic matching —á–µ—Ä–µ–∑ embeddings"""
        task_emb = self.model.encode(task_description)
        
        similarities = []
        for server_name, server_emb in self.server_embeddings.items():
            # Cosine similarity
            import numpy as np
            similarity = np.dot(task_emb, server_emb) / (
                np.linalg.norm(task_emb) * np.linalg.norm(server_emb)
            )
            similarities.append((server_name, float(similarity)))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º top_k
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def _keyword_match(
        self, 
        task_description: str, 
        top_k: int
    ) -> list[tuple[str, float]]:
        """Keyword matching (fallback)"""
        task_lower = task_description.lower()
        matches = []
        
        for server_name, caps in self.capabilities.registry.items():
            score = 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º covers_technologies
            for tech in caps.covers_technologies:
                if tech.lower() in task_lower:
                    score += 0.5
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º purpose
            if any(word in task_lower for word in caps.purpose.lower().split()):
                score += 0.3
            
            if score > 0:
                matches.append((server_name, min(score, 1.0)))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches[:top_k]
```

### 3. analyzer.py - Enhanced Task Analyzer

```python
"""
Enhanced Task Analyzer - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è keyword –∏ semantic –∞–Ω–∞–ª–∏–∑–∞
"""

from dataclasses import dataclass
from typing import list
from .router import SemanticRouter
from .capabilities import CapabilitiesRegistry


@dataclass
class TaskAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á–∏"""
    required_servers: list[str]
    recommended_servers: list[str]
    activation_order: list[str]
    estimated_tokens: int
    confidence: float
    detected_technologies: list[str]


class EnhancedTaskAnalyzer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–¥–∞—á"""
    
    def __init__(
        self, 
        capabilities_registry: CapabilitiesRegistry,
        semantic_router: SemanticRouter
    ):
        self.capabilities = capabilities_registry
        self.router = semantic_router
    
    def analyze_task(self, task_description: str) -> TaskAnalysis:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á—É –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""
        # 1. Keyword-based –∞–Ω–∞–ª–∏–∑
        keyword_servers = self._keyword_analysis(task_description)
        
        # 2. Semantic –∞–Ω–∞–ª–∏–∑
        semantic_matches = self.router.match_servers(task_description, top_k=5)
        semantic_servers = [s for s, _ in semantic_matches if s not in keyword_servers]
        
        # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_servers = list(set(keyword_servers + semantic_servers))
        
        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        detected_techs = self._detect_technologies(task_description)
        
        # 5. –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (context7 –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫)
        required = []
        recommended = []
        
        for server in all_servers:
            caps = self.capabilities.get(server)
            if caps:
                # –ï—Å–ª–∏ —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º context7
                if caps.covers_technologies and "context7" not in all_servers:
                    if any(tech in task_description.lower() 
                           for tech in caps.covers_technologies):
                        recommended.append("context7")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
                for related in caps.related_servers:
                    if related not in all_servers and related not in recommended:
                        recommended.append(related)
        
        required = all_servers
        all_servers = required + recommended
        
        # 6. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–æ—Ä—è–¥–æ–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        activation_order = self._optimize_order(all_servers)
        
        # 7. –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        estimated_tokens = self._estimate_tokens(all_servers)
        
        # 8. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = self._calculate_confidence(
            task_description, 
            required, 
            semantic_matches
        )
        
        return TaskAnalysis(
            required_servers=required,
            recommended_servers=recommended,
            activation_order=activation_order,
            estimated_tokens=estimated_tokens,
            confidence=confidence,
            detected_technologies=detected_techs
        )
    
    def _keyword_analysis(self, task: str) -> list[str]:
        """Keyword-based –∞–Ω–∞–ª–∏–∑"""
        task_lower = task.lower()
        matched = []
        
        for server_name, caps in self.capabilities.registry.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º covers_technologies
            if any(tech.lower() in task_lower for tech in caps.covers_technologies):
                matched.append(server_name)
        
        return matched
    
    def _detect_technologies(self, task: str) -> list[str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–ø–æ–º—è–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"""
        task_lower = task.lower()
        technologies = []
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏–∑ capabilities
        all_techs = set()
        for caps in self.capabilities.registry.values():
            all_techs.update(caps.covers_technologies)
        
        # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        for tech in all_techs:
            if tech.lower() in task_lower:
                technologies.append(tech)
        
        return technologies
    
    def _optimize_order(self, servers: list[str]) -> list[str]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (context7), –ø–æ—Ç–æ–º –æ—Å–Ω–æ–≤–Ω—ã–µ
        deps = [s for s in servers if s == "context7"]
        main = [s for s in servers if s != "context7"]
        return deps + main
    
    def _estimate_tokens(self, servers: list[str]) -> int:
        """–û—Ü–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤"""
        # –ü—Ä–∏–º–µ—Ä–Ω–æ 1000 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
        return len(servers) * 1000
    
    def _calculate_confidence(
        self, 
        task: str, 
        required: list[str],
        semantic_matches: list[tuple[str, float]]
    ) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        if not required:
            return 0.0
        
        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–∏–π confidence –∏–∑ semantic matches
        if semantic_matches:
            avg_confidence = sum(score for _, score in semantic_matches) / len(semantic_matches)
            return min(1.0, avg_confidence)
        
        # Fallback: –±–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        return 0.7 if required else 0.0
```

### 4. telemetry.py - Observability

```python
"""
Telemetry –¥–ª—è observability
"""

import json
import time
import logging
from datetime import datetime
from typing import Optional
from dataclasses import dataclass, asdict


@dataclass
class ActivationEvent:
    """–°–æ–±—ã—Ç–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
    server: str
    reason: str
    success: bool
    latency_ms: float
    timestamp: float
    error: Optional[str] = None


class Telemetry:
    """Telemetry –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, log_file: Optional[str] = None):
        self.logger = logging.getLogger("telemetry")
        self.log_file = log_file
        self.events: list[ActivationEvent] = []
    
    def log_activation(
        self,
        server: str,
        reason: str,
        success: bool,
        latency_ms: float = 0.0,
        error: Optional[str] = None
    ):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏—é —Å–µ—Ä–≤–µ—Ä–∞"""
        event = ActivationEvent(
            server=server,
            reason=reason,
            success=success,
            latency_ms=latency_ms,
            timestamp=time.time(),
            error=error
        )
        
        self.events.append(event)
        
        # –õ–æ–≥–∏—Ä—É–µ–º
        log_data = asdict(event)
        log_data["timestamp"] = datetime.fromtimestamp(event.timestamp).isoformat()
        
        self.logger.info(json.dumps(log_data))
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(json.dumps(log_data) + "\n")
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.events:
            return {}
        
        total = len(self.events)
        successful = sum(1 for e in self.events if e.success)
        failed = total - successful
        
        avg_latency = sum(e.latency_ms for e in self.events) / total if total > 0 else 0
        
        server_counts = {}
        for event in self.events:
            server_counts[event.server] = server_counts.get(event.server, 0) + 1
        
        return {
            "total_activations": total,
            "successful": successful,
            "failed": failed,
            "avg_latency_ms": avg_latency,
            "server_counts": server_counts
        }
```

### 5. –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π server.py - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```python
# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç—ã
from .discovery import ServerDiscovery, ServerMetadata
from .registry import ServerRegistry
from .capabilities import CapabilitiesRegistry
from .analyzer import EnhancedTaskAnalyzer
from .router import SemanticRouter
from .profiles import find_matching_profile, get_all_profiles, SERVER_PROFILES
from .monitor import UsageMonitor
from .telemetry import Telemetry

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
discovery = ServerDiscovery()
registry = ServerRegistry(discovery)
capabilities_registry = CapabilitiesRegistry()
semantic_router = SemanticRouter(capabilities_registry)
task_analyzer = EnhancedTaskAnalyzer(capabilities_registry, semantic_router)
usage_monitor = UsageMonitor()
telemetry = Telemetry()

# –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ
# (—Å–º. FINAL_HYBRID_SOLUTION.md –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–¥–∞)

# –í main() –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
async def initialize():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    logger.info("Initializing Smart MCP Orchestrator v2.0...")
    
    # 1. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–æ–≤
    await registry.refresh(force=True)
    logger.info(f"Discovered {len(registry.servers)} servers")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ capabilities
    logger.info(f"Loaded capabilities for {len(capabilities_registry.registry)} servers")
    
    # 3. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    enabled = get_enabled_servers()
    state.active_servers = set(enabled) & set(registry.servers.keys())
    
    if state.active_servers:
        logger.info(f"Found active: {state.active_servers}")
        for server in state.active_servers:
            state.server_tools_cache[server] = get_server_tools(server)
            usage_monitor.track_activation(server)
    
    logger.info("Ready!")

def main():
    """Main entry point"""
    asyncio.run(initialize())
    mcp.run()
```

---

## üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
Smart MCP Orchestrator v2.0
‚îú‚îÄ‚îÄ Dynamic Discovery (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ)
‚îú‚îÄ‚îÄ Capabilities Registry (—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ ‚Üí —Å–µ—Ä–≤–µ—Ä—ã)
‚îú‚îÄ‚îÄ Smart Routing (keyword + semantic)
‚îú‚îÄ‚îÄ Task Analyzer (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
‚îú‚îÄ‚îÄ Server Profiles (–≥–æ—Ç–æ–≤—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏)
‚îú‚îÄ‚îÄ Usage Monitor (–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥)
‚îú‚îÄ‚îÄ Telemetry (observability)
‚îî‚îÄ‚îÄ 8 Core Tools
    ‚îú‚îÄ‚îÄ get_capabilities() - compact catalog
    ‚îú‚îÄ‚îÄ suggest_servers() - —É–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    ‚îú‚îÄ‚îÄ activate_servers() - –∞–∫—Ç–∏–≤–∞—Ü–∏—è —Å tools
    ‚îú‚îÄ‚îÄ activate_profile() - –ø—Ä–æ—Ñ–∏–ª–∏
    ‚îú‚îÄ‚îÄ deactivate_servers() - –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è
    ‚îú‚îÄ‚îÄ get_status() - —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    ‚îú‚îÄ‚îÄ monitor_usage() - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    ‚îî‚îÄ‚îÄ optimize_servers() - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
```

**–ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è + —É–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ + –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ = Senior AI Engineer —Ä–µ—à–µ–Ω–∏–µ!** üöÄ
